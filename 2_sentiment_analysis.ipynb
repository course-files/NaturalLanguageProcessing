{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "| Key              | Value                                                                                                                                                                                                                                                                           |\n",
    "|:-----------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Course Codes** | BBT 4206, BFS 4102, and BCM 3103                                                                                                                                                                                                                                                |\n",
    "| **Course Names** | BBT 4206: Business Intelligence II (Week 7-9 of 13),<br/>BFS 4102: Advanced Business Data Analytics (Week 7-9 of 13) and <br/>BCM 3103: Business Intelligence and Data Analytics (Week 10-12 of 13)                                                                             |\n",
    "| **Semester**     | August to November 2025                                                                                                                                                                                                                                                         |\n",
    "| **Lecturer**     | Allan Omondi                                                                                                                                                                                                                                                                    |\n",
    "| **Contact**      | aomondi@strathmore.edu                                                                                                                                                                                                                                                          |\n",
    "| **Note**         | The lecture contains both theory and practice.<br/>This notebook forms part of the practice.<br/>It is intended for educational purpose only.<br/>Recommended citation: [BibTex](https://github.com/course-files/SentimentAnalysis/raw/refs/heads/main/RecommendedCitation.bib) |\n",
    "\n",
    "**Business context**: A business has set a strategic objective *to increase the monthly average customer rating to 3.8/5 by the end of the current financial year*. The business tracks two Key Performance Indicators (KPIs) from the customer perspective:\n",
    "\n",
    "1. **Lagging KPI**: Monthly average customer rating\n",
    "2. **Leading KPI**: The number of positive, neutral, and negative reviews received per theme/topic\n",
    "\n",
    "The business wants to leverage Natural Language Processing (NLP) as part of AI to create a predictive model that can predict a customer's sentiment based on their textual comments. The model needs to be trained on historical customer reviews and ratings to identify patterns and trends in customer sentiment. This will help the business to consider the qualitative aspects of customer feedback, not just the quantitative ratings, despite the large number of customers.\n",
    "\n",
    "**Dataset:** The original dataset by **Ott and Arvidsson (2023)** consists of 878,561 reviews (1.3GB) from 4,333 hotels crawled from **TripAdvisor ([https://www.tripadvisor.com/](https://www.tripadvisor.com/))**.\n",
    "Points to note:\n",
    "- Some reviews are written in French. Source: [https://www.cs.cmu.edu/~jiweil/html/hotel-review.html](https://www.cs.cmu.edu/~jiweil/html/hotel-review.html) or [https://www.kaggle.com/datasets/joebeachcapital/hotel-reviews](https://www.kaggle.com/datasets/joebeachcapital/hotel-reviews).\n",
    "- We use a scaled-down version of the dataset (a sample) that contains 50,000 reviews for the sake of performance and efficiency in a lab setting for educational purposes.\n",
    "\n",
    "| Feature            | Description                                                                           |\n",
    "|--------------------|---------------------------------------------------------------------------------------|\n",
    "| `date`             | Indicates the date when the review was written                                        |\n",
    "| `offering_id`      | Indicates the ID of the hotel that the customer stayed in                             |\n",
    "| `date_stayed`      | Indicates the date when the customer stayed at the hotel                              |\n",
    "| `text`             | Contains the review text                                                              |\n",
    "| `rating_overall`   | Overall rating given by the customer (1 to 5 stars; 1 is the worst and 5 is the best) |\n",
    "| `is_english`       | Indicates whether the review is written in English (`True`) or not (`False`)          |\n",
    "| `author_username`  | Indicates the username of the customer who wrote the review                           |\n",
    "| `author_location`  | Indicates the location of the customer who wrote the review                           |"
   ],
   "id": "c87a85e74d890c5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 1: Import the necessary libraries",
   "id": "344e6f2e4982f64e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Purpose**: This chunk imports all the necessary libraries for data analysis, machine learning, and visualization.\n",
    "\n",
    "1. **For file and system operations [urllib3](https://urllib3.readthedocs.io/en/stable/) and [joblib](https://joblib.readthedocs.io/en/stable/)**\n",
    "    - `urllib.request` is used for opening and downloading data from URLs.\n",
    "    - `os` provides functions for interacting with the operating system, such as file and directory management.\n",
    "    - `joblib` and `picle` are used for saving and loading Python objects, such as machine learning models, to and from disk.\n",
    "\n",
    "2. **For data manipulation - [pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html) and [numpy](https://numpy.org/doc/stable/index.html):**\n",
    "    - `pandas as pd`: For loading the dataset, creating and managing DataFrames, data manipulation and analysis using DataFrames\n",
    "    - `numpy as np`: For numerical operations and array manipulations\n",
    "\n",
    "3. **For text preprocessing - [re](https://docs.python.org/3/library/re.html)**\n",
    "    - `re`: For regular expression operations to clean and preprocess text data\n",
    "    - `ast`: For converting strings to Python objects.\n",
    "\n",
    "4. **For sentiment analysis - [nltk](https://www.nltk.org/book/) and [scikit-learn](https://scikit-learn.org/)**\n",
    "    - `nltk` is a Python package for natural language processing. It provides a variety of tools for analyzing textual data, including tokenization, part-of-speech tagging, named entity recognition, sentiment analysis, and more.\n",
    "    - `stopwords` is a list of stopwords in the English language. It is used to remove stopwords from textual data before processing.\n",
    "    - `PorterStemmer` is a stemming algorithm that reduces words to their root form.\n",
    "\n",
    "    - `TfidfVectorizer` is a vectorizer that converts text documents to vectors of TF-IDF features.\n",
    "    - `make_pipeline` is a function that creates a pipeline of preprocessing and model training steps.\n",
    "    - `LogisticRegression` is a classification algorithm that uses logistic regression to predict binary labels.\n",
    "    - `accuracy_score` is a function that calculates the accuracy of a model's predictions.\n",
    "    - `confusion_matrix` is a function that creates a confusion matrix for a classification model.\n",
    "    - `classification_report` is a function that creates a classification report for a classification model.\n",
    "    - `train_test_split` is a function that splits data into training and test sets.\n",
    "    - `MultinomialNB` is a classification algorithm that uses the multinomial naive Bayes algorithm to predict binary labels.\n",
    "    - `DecisionTreeClassifier` is a classification algorithm that uses decision trees to predict binary labels.\n",
    "    - `RandomForestClassifier` is a classification algorithm that uses random forests to predict binary labels.\n",
    "    - `precision_recall_fscore_support` is a function that calculates precision, recall, F1 score, and support for a classification model.\n",
    "\n",
    "5. **For data visualization - [matplotlib](https://matplotlib.org/stable/gallery/index.html) and [seaborn](https://seaborn.pydata.org/)**\n",
    "    - `matplotlib.pyplot as plt`: For basic plotting functionality\n",
    "    - `seaborn as sns`: For advanced plotting functionality\n",
    "    - `WordCloud` is a word cloud visualization tool that generates word clouds from text data.\n",
    "\n",
    "6. **For formatting of display text**\n",
    "    - `textwrap` is used to format and wrap text for improved readability in output.\n",
    "\n",
    "7. **For mathematical operations**\n",
    "    - `math` supplies mathematical functions like ceiling, floor, and trigonometric operations."
   ],
   "id": "8c38f456e41afde8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For file and system operations\n",
    "import urllib.request\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# For data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For text preprocessing\n",
    "import re\n",
    "import ast\n",
    "\n",
    "# For sentiment analysis\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "# nltk.download('all')  # Downloads all NLTK data (large download) approx. 3.5GB !\n",
    "nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import textwrap\n",
    "\n",
    "# Set visual styles for the whole notebook\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "%matplotlib inline\n",
    "\n",
    "# For suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "39f16805afecf341",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 2: Load the data",
   "id": "c66243585fef84a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset_path = './data/processed_scaled_down_reviews_with_topics.csv'\n",
    "url = 'https://github.com/course-files/SentimentAnalysis/raw/refs/heads/main/data/processed_scaled_down_reviews_with_topics.csv'\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(\"Downloading dataset...\")\n",
    "    if not os.path.exists('./data'):\n",
    "        os.makedirs('./data')\n",
    "    urllib.request.urlretrieve(url, dataset_path)\n",
    "    print(\"✅ Dataset downloaded\")\n",
    "else:\n",
    "    print(\"✅ Dataset already exists locally\")\n",
    "\n",
    "customer_reviews_data = pd.read_csv(dataset_path, encoding='utf-8')\n",
    "print(f\"\\nLoaded: {len(customer_reviews_data)} reviews\")\n",
    "print(\"Sample review:\")\n",
    "print(customer_reviews_data['text'].iloc[0][:100] + \"...\")"
   ],
   "id": "359be443cedf67ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- The **ratings** column contains values that look like dictionaries, but they are actually stored as strings (e.g., \"{'service': 5.0, 'cleanliness': 5.0, ...}\"). This means that Python sees them as text, not as actual dictionaries.\n",
    "- The code therefore uses `ast.literal_eval` to safely convert each string in the **ratings** column into an actual Python dictionary. The result is stored in a new column called ratings_dict."
   ],
   "id": "e52a151df266556d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"List of all features (columns) before splitting the ratings:\")\n",
    "print(customer_reviews_data.columns.tolist())\n",
    "\n",
    "# Convert 'ratings' from a String to a Python dictionary\n",
    "customer_reviews_data['ratings_dict'] = customer_reviews_data['ratings'].apply(ast.literal_eval)\n",
    "\n",
    "# Expand the Python dictionary into separate columns\n",
    "ratings_df = customer_reviews_data['ratings_dict'].apply(pd.Series)\n",
    "customer_reviews_data = pd.concat([customer_reviews_data, ratings_df], axis=1)\n",
    "\n",
    "print(\"List of all features (columns) after splitting the ratings:\")\n",
    "print(customer_reviews_data.columns.tolist())"
   ],
   "id": "64ea52922b6f2fd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Preview data\n",
    "print(\"\\nFirst 5 reviews:\")\n",
    "display(customer_reviews_data.head())\n",
    "\n",
    "print(\"\\nLast 5 reviews:\")\n",
    "display(customer_reviews_data.tail())"
   ],
   "id": "a73b45fa7653d3e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now plot the overall rating\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x='overall', data=customer_reviews_data, palette='viridis')\n",
    "plt.title('Distribution of Overall Rating')\n",
    "plt.xlabel('Rating (1-5 stars)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ],
   "id": "9dcf28176d972ffc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x='service', data=customer_reviews_data, palette='viridis')\n",
    "plt.title('Distribution of Customer Service Rating')\n",
    "plt.xlabel('Rating (1-5 stars)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ],
   "id": "cf75e44ec4816572",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Updated list of all rating columns\n",
    "rating_cols = [\n",
    "    'service', 'cleanliness', 'overall', 'value', 'location',\n",
    "    'sleep_quality', 'rooms', 'check_in_front_desk', 'business_service_(e_g_internet_access)'\n",
    "]\n",
    "\n",
    "n = len(rating_cols)\n",
    "blues = sns.color_palette(\"Blues\", n_colors=n//2 + n%2)\n",
    "greys = sns.color_palette(\"Greys\", n_colors=n//2)\n",
    "custom_palette = blues + greys\n",
    "\n",
    "# The melt function in pandas transforms your DataFrame from wide format (many\n",
    "# columns for each rating type) to long format (one column for rating type, one\n",
    "# for value). This is useful for plotting or analysis where you want all\n",
    "# ratings in a single column.\n",
    "ratings_long = customer_reviews_data.melt(\n",
    "    value_vars=rating_cols, var_name='Rating_Type', value_name='Rating'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "ax = sns.countplot(x='Rating', hue='Rating_Type', data=ratings_long, palette=custom_palette)\n",
    "\n",
    "plt.title('Distribution of All Ratings')\n",
    "plt.xlabel('Rating (1-5 stars)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "# for container in ax.containers:\n",
    "#     ax.bar_label(container, fmt='%d', label_type='edge')\n",
    "\n",
    "# Format y-axis with commas\n",
    "ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{int(x):,}'))\n",
    "\n",
    "plt.legend(title='Rating Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "600b8324bac8632e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3: Data Preprocessing\n",
    "#### Sentiment Label Creation"
   ],
   "id": "1c9113b6b9e56f6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert ratings to sentiment categories\n",
    "def rating_to_sentiment(rating):\n",
    "    if rating <= 2: return 'negative'\n",
    "    elif rating == 3: return 'neutral'\n",
    "    else: return 'positive'\n",
    "\n",
    "customer_reviews_data['sentiment'] = customer_reviews_data['service'].apply(rating_to_sentiment)\n",
    "\n",
    "# Check sentiment distribution\n",
    "sentiment_counts = customer_reviews_data['service'].value_counts()\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(sentiment_counts)"
   ],
   "id": "f8a893d17137866f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.2. Text Cleaning",
   "id": "bf76f9242e9ea3d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Processing includes:\n",
    "- Lowercasing\n",
    "- Removing special characters/numbers\n",
    "- Stopword removal (e.g., \"the\", \"and\")\n",
    "- Porter stemming (e.g., \"loved\" → \"love\")"
   ],
   "id": "573d52d89cad657f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize NLP tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercase conversion\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters/numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Apply stemming\n",
    "    stemmed = [stemmer.stem(word) for word in filtered]\n",
    "\n",
    "    return \" \".join(stemmed)\n",
    "\n",
    "# Apply cleaning\n",
    "customer_reviews_data['clean_text_for_sa'] = customer_reviews_data['clean_text'].apply(clean_text)\n",
    "\n",
    "# Show a transformation example\n",
    "print(\"\\nOriginal review:\", customer_reviews_data['clean_text'][0])\n",
    "print(\"\\n\\nCleaned review:\", customer_reviews_data['clean_text_for_sa'][0])"
   ],
   "id": "878847fda5ff00a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 4: Feature Engineering\n",
    "\n",
    "Convert text to numerical features using TF-IDF\n",
    "\n",
    "Why TF-IDF?\n",
    "- Weights words based on its importance in the document versus its importance in the corpus\n",
    "- Better than raw counts (using `CountVectorizer`) for sentiment analysis"
   ],
   "id": "4251e0e38ddd2037"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "# Including trigrams (ngram_range=(1,3)) allows the model to capture more\n",
    "# context and specific phrases, which can improve sentiment analysis,\n",
    "# especially for phrases like \"not at all good\". However, it increases feature\n",
    "# space and may add noise if your dataset is small.\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,  # Limit vocabulary size\n",
    "    ngram_range=(1,3)   # Include unigrams, bigrams, and trigrams\n",
    ")\n",
    "\n",
    "# Create feature matrix\n",
    "X = tfidf.fit_transform(customer_reviews_data['clean_text_for_sa'])\n",
    "y = customer_reviews_data['sentiment']\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")"
   ],
   "id": "99559d4f8b7ac0e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For X_train\n",
    "X_train_df = pd.DataFrame(X_train[:5].toarray(), columns=tfidf.get_feature_names_out())\n",
    "display(X_train_df)\n",
    "\n",
    "# For X_test\n",
    "X_test_df = pd.DataFrame(X_test[:5].toarray(), columns=tfidf.get_feature_names_out())\n",
    "display(X_test_df)"
   ],
   "id": "7a74b6b47920c72d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 5: Model Training\n",
    "\n",
    "- The purpose of training a model is to create a system that can automatically predict sentiment (positive, neutral, or negative) from raw customer feedback text. Specific benefits include:\n",
    "\n",
    "1. **Automate Sentiment Analysis**\n",
    "    - Replace manual review reading with AI-powered classification\n",
    "    - Example: Automatically tag 10,000+ reviews as positive/neutral/negative\n",
    "\n",
    "2. **Learn Language Patterns**\n",
    "    - The model learns which words/phrases correlate with each sentiment:\n",
    "      - Positive: \"great\", \"excellent service\", \"friendly staff\"\n",
    "      - Negative: \"terrible\", \"broken\", \"rude\"\n",
    "      - Neutral: \"average\", \"acceptable\", \"standard\"\n",
    "\n",
    "3. **Generalize to New Reviews**\n",
    "    - Once trained, it can predict sentiment for never-before-seen reviews\n",
    "    - Example:\n",
    "    ```\n",
    "    predict_sentiment(\"The concierge was amazingly helpful!\")\n",
    "    # Output: ('positive', 0.92) → 92% confidence\n",
    "    ```\n",
    "---\n",
    "- Real-World Applications\n",
    "1. **Customer Experience Monitoring**\n",
    "    - Track sentiment trends over time\n",
    "    - Example: \"Negative reviews increased 20% this month\"\n",
    "\n",
    "2. **Automatic Alerting**\n",
    "    - Flag negative reviews for immediate follow-up\n",
    "\n",
    "3. **Product Improvement**\n",
    "    - Identify frequent issues in negative reviews\n",
    "    - Example: \"57% of negative reviews mention 'broken AC'\"\n",
    "\n",
    "---\n",
    "**Why Not Use Rules Instead?**\n",
    "- A rules-based approach (e.g., \"if 'great' in text → positive\") fails because:\n",
    "    - Context matters: \"not great\" is negative. This is why we use bigrams and trigrams.\n",
    "    - New phrases emerge: \"game-changing UX\" (positive) will not be in predefined rules.\n",
    "    - Scalability: It is challenging to manually maintain rules for 10,000+ unique phrases.\n",
    "\n",
    "- The ML model automatically learns these nuances from data.\n",
    "---\n",
    "**Sentiment Analysis Model Training Pipeline**\n",
    "- Input: Cleaned text → TF-IDF features\n",
    "- Learning: Adjusts weights for each word's sentiment contribution\n",
    "- Output: Prediction function f(text) → sentiment\n",
    "- Validation: Tests on held-out reviews to verify accuracy"
   ],
   "id": "f079c0a9ab8ceaf1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=53),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=5, random_state=53),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=5, random_state=53, n_jobs=1)\n",
    "    # \"Support Vector Machine\": SVC(kernel='linear', probability=True, random_state=53)\n",
    "}"
   ],
   "id": "1f72325853541a7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Training using 10-Fold Cross Validation with 3 Repeats",
   "id": "b57e048d326597b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate\n",
    "\n",
    "scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=53)\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Cross-validating {name}...\")\n",
    "    scores = cross_validate(\n",
    "        model, X, y,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    # 30 folds: 10 splits x 3 repeats\n",
    "    results_df = pd.DataFrame({\n",
    "        'Fold': range(1, len(scores['test_accuracy']) + 1),\n",
    "        'Accuracy': scores['test_accuracy'],\n",
    "        'Precision': scores['test_precision_weighted'],\n",
    "        'Recall': scores['test_recall_weighted'],\n",
    "        'F1-Score': scores['test_f1_weighted']\n",
    "    })\n",
    "    print(f\"\\n{name} - Raw Cross-Validation Metrics:\")\n",
    "    display(results_df)\n",
    "    cv_results[name] = results_df"
   ],
   "id": "d3f7a1ef8459328b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "summary = []\n",
    "for name, df in cv_results.items():\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'Accuracy Mean': df['Accuracy'].mean(),\n",
    "        'Accuracy Std': df['Accuracy'].std(),\n",
    "        'Precision Mean': df['Precision'].mean(),\n",
    "        'Precision Std': df['Precision'].std(),\n",
    "        'Recall Mean': df['Recall'].mean(),\n",
    "        'Recall Std': df['Recall'].std(),\n",
    "        'F1-Score Mean': df['F1-Score'].mean(),\n",
    "        'F1-Score Std': df['F1-Score'].std()\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(summary).sort_values('F1-Score Mean', ascending=False)\n",
    "display(results_df)"
   ],
   "id": "24ab7e4c7f3b1617",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Comparison Visualization",
   "id": "e3afdc0ab3ec2502"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot mean metric comparison from cross-validation\n",
    "metrics_to_plot = ['Accuracy Mean', 'Precision Mean', 'Recall Mean', 'F1-Score Mean']\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = results_df.set_index('Model')[metrics_to_plot].plot(kind='bar', width=0.8)\n",
    "plt.title('Model Performance Comparison (Cross-Validation Means)', pad=20)\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add value labels on each bar\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.3f', label_type='edge', fontsize=10)\n",
    "\n",
    "plt.show()"
   ],
   "id": "ad0862c13df3a5b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### \"Best\" Model Selection (Based on the F1-Score)",
   "id": "618da131d8315074"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select the best model type based on the F1-Score\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model_type = models[best_model_name]\n",
    "\n",
    "# Retrain the best model on training data\n",
    "best_model = best_model_type.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n The Best Performing Model: {best_model_name}\")\n",
    "print(f\" F1-Score (CV Mean): {results_df.iloc[0]['F1-Score Mean']:.3f}\")\n",
    "\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test, best_model.predict(X_test)))\n",
    "\n",
    "# Confusion matrix visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, best_model.predict(X_test))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=best_model.classes_,\n",
    "            yticklabels=best_model.classes_)\n",
    "plt.title(f'Confusion Matrix for {best_model_name}', pad=15)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ],
   "id": "39ed20c941b69a3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 6: Feature Analysis",
   "id": "a4c0a531876171d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Top Predictive Words per Class",
   "id": "ec3e66a4f932e37c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Get the top 20 most important features\n",
    "    feature_imp = pd.Series(best_model.feature_importances_,\n",
    "                           index=tfidf.get_feature_names_out()\n",
    "                          ).sort_values(ascending=False)[:20]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    feature_imp.sort_values().plot(kind='barh', color='darkcyan')\n",
    "    plt.title('Top 20 Predictive Features (for non-linear models)', pad=15)\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.show()\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    # For linear models like Logistic Regression\n",
    "    # because they use the coef_ attribute instead of feature_importances_\n",
    "    print(\"\\nTop Predictive Words per Class (for linear models):\")\n",
    "    for i, class_name in enumerate(best_model.classes_):\n",
    "        top10 = np.argsort(best_model.coef_[i])[-10:]\n",
    "        words = tfidf.get_feature_names_out()[top10]\n",
    "        print(f\"{class_name.upper()}: {', '.join(words)}\")"
   ],
   "id": "b587a221cf9192d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Word Clouds by Sentiment",
   "id": "7359056a4b55ea49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate word clouds with vertical lines between plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i, sentiment in enumerate(['positive', 'neutral', 'negative']):\n",
    "    text = \" \".join(customer_reviews_data[customer_reviews_data['sentiment'] == sentiment]['text'])\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        max_words=100\n",
    "    ).generate(text)\n",
    "\n",
    "    axes[i].imshow(wordcloud, interpolation='bilinear')\n",
    "    axes[i].set_title(f\"{sentiment.capitalize()} Reviews\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Draw vertical lines between subplots\n",
    "for i in range(1, 3):\n",
    "    fig.lines.append(plt.Line2D(\n",
    "        [i / 3, i / 3], [0, 1], color='black', linewidth=1, transform=fig.transFigure\n",
    "    ))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b1e23bd0b227c816",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 7: Display Sentiment Counts per Topic",
   "id": "5a26797c7c3f72ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a prediction function which can then be served through an API\n",
    "def predict_sentiment(text):\n",
    "    try:\n",
    "        # Clean and vectorize text\n",
    "        cleaned_text = clean_text(text)\n",
    "        text_vector = tfidf.transform([cleaned_text])\n",
    "\n",
    "        # Predict and get confidence\n",
    "        pred = best_model.predict(text_vector)[0]\n",
    "        proba = best_model.predict_proba(text_vector).max()\n",
    "\n",
    "        return pred, round(proba, 3)\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {str(e)}\")\n",
    "        return None, 0.0"
   ],
   "id": "3d9805bfa8b74468",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# `tqdm` is a Python library that provides fast, extensible progress bars for\n",
    "# loops and iterable processing. It visually tracks the progress of tasks in\n",
    "# the terminal or Jupyter notebooks, making it easier to monitor long-running\n",
    "# operations such as data processing or model predictions.\n",
    "import tqdm\n",
    "\n",
    "# Apply prediction to each review and store results\n",
    "preds = []\n",
    "probas = []\n",
    "\n",
    "for text in tqdm.tqdm(customer_reviews_data['text'], desc=\"Predicting sentiment\"):\n",
    "    pred, proba = predict_sentiment(text)\n",
    "    preds.append(pred)\n",
    "    probas.append(proba)\n",
    "\n",
    "customer_reviews_data['predicted_sentiment'] = preds\n",
    "customer_reviews_data['prediction_confidence'] = probas\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "display(customer_reviews_data[['text', 'predicted_sentiment', 'prediction_confidence']].head())"
   ],
   "id": "efa10f31a73084a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to wrap text\n",
    "def wrap_labels(labels, width):\n",
    "    return ['\\n'.join(textwrap.wrap(label, width)) for label in labels]\n",
    "\n",
    "# Count sentiments per topic_label\n",
    "sentiment_counts = customer_reviews_data.groupby(['topic_label', 'predicted_sentiment']).size().unstack(fill_value=0)\n",
    "\n",
    "# Define custom colors for each sentiment\n",
    "sentiment_colors = {\n",
    "    'positive': 'green',\n",
    "    'neutral': 'orange',\n",
    "    'negative': 'red'\n",
    "}\n",
    "sentiment_order = ['positive', 'neutral', 'negative']\n",
    "colors = [sentiment_colors[s] for s in sentiment_order if s in sentiment_counts.columns]\n",
    "\n",
    "# Wrap x labels\n",
    "wrapped_labels = wrap_labels(sentiment_counts.index.astype(str), width=12)\n",
    "\n",
    "# Plot\n",
    "ax = sentiment_counts[sentiment_order].plot(kind='bar', stacked=False, figsize=(10,6), color=colors)\n",
    "ax.set_xticklabels(wrapped_labels, rotation=45, ha='right')\n",
    "plt.title('Sentiment Counts per Topic')\n",
    "plt.xlabel('Topic Label')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.legend(title='Sentiment')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add count labels on each bar\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%d', label_type='edge', fontsize=9)\n",
    "\n",
    "plt.show()"
   ],
   "id": "dc348bd7579914b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 8: Export the Results",
   "id": "500e20bf8458748e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the results as a CSV file for further analysis and reporting\n",
    "output_path = \"./data/processed_scaled_down_reviews_with_topics_and_sentiments.csv\"\n",
    "# Ensure the data directory exists\n",
    "if not os.path.exists('./data'):\n",
    "    os.makedirs('./data')\n",
    "# Save the CSV file regardless of environment\n",
    "customer_reviews_data.to_csv(output_path, index=False)\n",
    "print(f\"\\n✅ Topic Modeling and Sentiment Results saved to {output_path}\")\n",
    "\n",
    "# Provide a download link if running in Google Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(output_path)\n",
    "except ImportError:\n",
    "    print(\"❌ Not running in Google Colab, skipped dataset download link.\")\n",
    "\n",
    "# Save the trained sentiment classifier\n",
    "model_path = './model/sentiment_classifier.pkl'\n",
    "# Ensure the model directory exists\n",
    "if not os.path.exists('./model'):\n",
    "    os.makedirs('./model')\n",
    "# Save the model regardless of environment\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"✅ Model saved to {model_path}\")\n",
    "\n",
    "# Provide a download link if running in Google Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(model_path)\n",
    "except ImportError:\n",
    "    print(\"❌ Not running in Google Colab, skipped model download link.\")\n",
    "\n",
    "# Save the used vectorizer model\n",
    "vectorizer_path = './model/topic_vectorizer_using_tfidf.pkl'\n",
    "# Ensure the model directory exists\n",
    "if not os.path.exists('./model'):\n",
    "    os.makedirs('./model')\n",
    "# Save the model regardless of environment\n",
    "joblib.dump(tfidf, vectorizer_path)\n",
    "print(f\"✅ Vectorizer saved to {vectorizer_path}\")\n",
    "\n",
    "# Provide a download link if running in Google Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(vectorizer_path)\n",
    "except ImportError:\n",
    "    print(\"❌ Not running in Google Colab, skipped vectorizer download link.\")\n",
    "\n",
    "# # Save the topic label\n",
    "# label_path = './model/topic_labels.json'\n",
    "# # Ensure the model directory exists\n",
    "# if not os.path.exists('./model'):\n",
    "#     os.makedirs('./model')\n",
    "# # Save the topic labels regardless of environment\n",
    "# with open(label_path, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(topic_labels, f, ensure_ascii=False, indent=2)\n",
    "# print(f\"✅ Topic labels saved to {label_path}\")\n",
    "#\n",
    "# # Provide a download link if running in Google Colab\n",
    "# try:\n",
    "#     from google.colab import files\n",
    "#     files.download(label_path)\n",
    "# except ImportError:\n",
    "#     print(\"❌ Not running in Google Colab, skipped topic label download link.\")"
   ],
   "id": "c5789ffadba2f00f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 9: Model Deployment",
   "id": "ffe8ed58215fe188"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "import joblib\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Load persisted artifacts\n",
    "best_model = joblib.load('./model/sentiment_classifier.pkl')\n",
    "tfidf = joblib.load('./model/topic_vectorizer_using_tfidf.pkl')\n",
    "\n",
    "# Initialize NLP tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercase conversion\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters/numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Apply stemming\n",
    "    stemmed = [stemmer.stem(word) for word in filtered]\n",
    "\n",
    "    return \" \".join(stemmed)\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    try:\n",
    "        # Clean and vectorize text\n",
    "        cleaned_text = clean_text(text)\n",
    "        text_vector = tfidf.transform([cleaned_text])\n",
    "\n",
    "        # Predict and get confidence\n",
    "        pred = best_model.predict(text_vector)[0]\n",
    "        proba = best_model.predict_proba(text_vector).max()\n",
    "\n",
    "        return pred, round(proba, 3)\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {str(e)}\")\n",
    "        return None, 0.0"
   ],
   "id": "ecb2abbc80fc8f4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test Prediction Function",
   "id": "9569aa7a7951da41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test prediction\n",
    "\n",
    "sample_text = \"The room was clean and the staff were polite.\"\n",
    "# sample_text = \"The room was okay and the staff were average.\"\n",
    "# sample_text = \"The room was dirty and the staff were rude.\"\n",
    "# sample_text = \"Chumba kilikuwa kichafu na wafanyakazi walikuwa wakorofi.\"\n",
    "\n",
    "prediction, confidence = predict_sentiment(sample_text)\n",
    "print(f\"\\nPrediction Example:\")\n",
    "print(f\"Text: '{sample_text}'\")\n",
    "print(f\"Sentiment: {prediction} (Confidence: {confidence:.1%})\")"
   ],
   "id": "351a86fe693434a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# References\n",
    "Alam, H., Ryu, W.-J., & Lee, S. (2016). Joint multi-grain topic sentiment: modeling semantic aspects for online reviews. Information Sciences, 339, 206-223. https://doi.org/10.1016/j.ins.2016.01.013"
   ],
   "id": "bea930cf9957617d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
